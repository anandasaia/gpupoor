[{"clientCode": "import flwr as fl\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, Subset, random_split\nfrom torchvision import datasets, transforms\nfrom model import SimpleCNN\nimport time\nimport uuid\nimport random\n\nTOTAL_DATASET_SIZE = 1000  # Total number of images to use from MNIST\nDATASET_PERCENTAGE = 100\nMODEL_ID = ''\nETH_ADDRESS = ''\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = SimpleCNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\nfull_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n\n# Select a random subset of TOTAL_DATASET_SIZE from the full dataset\nindices = torch.randperm(len(full_dataset))[:TOTAL_DATASET_SIZE]\nsubset_dataset = Subset(full_dataset, indices)\n\n# Calculate the number of samples to use based on the percentage\nnum_samples = int(len(subset_dataset) * DATASET_PERCENTAGE / 100)\n\n# Create a stratified subset\nclass_indices = [[] for _ in range(10)]\nfor idx in indices:\n    _, label = full_dataset[idx]\n    class_indices[label].append(idx)\n\nsubset_indices = []\nfor class_idx in class_indices:\n    # Ensure that the sampling is within the bounds of each class's available indices\n    num_samples_per_class = int(len(class_idx) * DATASET_PERCENTAGE / 100)\n    subset_indices.extend(random.sample(class_idx, num_samples_per_class))\n\n# Correctly create the dataset from the subset indices\ndataset = Subset(full_dataset, subset_indices)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n\nclass MNISTClient(fl.client.NumPyClient):\n    def __init__(self):\n        super().__init__()\n        self.client_id = str(uuid.uuid4())\n\n    def get_parameters(self, config=None):\n        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        params_dict = zip(model.state_dict().keys(), parameters)\n        state_dict = {k: torch.tensor(v).to(device) for k, v in params_dict}\n        model.load_state_dict(state_dict)\n\n    def fit(self, parameters, config):\n        self.set_parameters(parameters)\n        model.train()\n        start_time = time.time()\n        for epoch in range(1):\n            for images, labels in train_loader:\n                images, labels = images.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n        compute_time = time.time() - start_time\n        return self.get_parameters(), len(train_loader.dataset), {\"compute_time\": compute_time, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\n    def evaluate(self, parameters, config):\n        self.set_parameters(parameters)\n        model.eval()\n        loss = 0\n        correct = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss += criterion(outputs, labels).item()\n                _, predicted = torch.max(outputs.data, 1)\n                correct += (predicted == labels).sum().item()\n        accuracy = correct / len(val_loader.dataset)\n        return loss, len(val_loader.dataset), {\"accuracy\": accuracy, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\nfl.client.start_client(server_address=\"localhost:8080\", client=MNISTClient().to_client())", "modelCode": "import torch\nimport torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n        self.fc1 = nn.Linear(7*7*64, 1000)\n        self.fc2 = nn.Linear(1000, 10)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = x.view(-1, 7*7*64)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x", "amount": "0.00001", "id": 1720962385517}, {"clientCode": "import flwr as fl\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, Subset, random_split\nfrom torchvision import datasets, transforms\nfrom model import SimpleCNN\nimport time\nimport uuid\nimport random\n\nTOTAL_DATASET_SIZE = 1000  # Total number of images to use from MNIST\nDATASET_PERCENTAGE = 100\nMODEL_ID = ''\nETH_ADDRESS = ''\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = SimpleCNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\nfull_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n\n# Select a random subset of TOTAL_DATASET_SIZE from the full dataset\nindices = torch.randperm(len(full_dataset))[:TOTAL_DATASET_SIZE]\nsubset_dataset = Subset(full_dataset, indices)\n\n# Calculate the number of samples to use based on the percentage\nnum_samples = int(len(subset_dataset) * DATASET_PERCENTAGE / 100)\n\n# Create a stratified subset\nclass_indices = [[] for _ in range(10)]\nfor idx in indices:\n    _, label = full_dataset[idx]\n    class_indices[label].append(idx)\n\nsubset_indices = []\nfor class_idx in class_indices:\n    # Ensure that the sampling is within the bounds of each class's available indices\n    num_samples_per_class = int(len(class_idx) * DATASET_PERCENTAGE / 100)\n    subset_indices.extend(random.sample(class_idx, num_samples_per_class))\n\n# Correctly create the dataset from the subset indices\ndataset = Subset(full_dataset, subset_indices)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n\nclass MNISTClient(fl.client.NumPyClient):\n    def __init__(self):\n        super().__init__()\n        self.client_id = str(uuid.uuid4())\n\n    def get_parameters(self, config=None):\n        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        params_dict = zip(model.state_dict().keys(), parameters)\n        state_dict = {k: torch.tensor(v).to(device) for k, v in params_dict}\n        model.load_state_dict(state_dict)\n\n    def fit(self, parameters, config):\n        self.set_parameters(parameters)\n        model.train()\n        start_time = time.time()\n        for epoch in range(1):\n            for images, labels in train_loader:\n                images, labels = images.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n        compute_time = time.time() - start_time\n        return self.get_parameters(), len(train_loader.dataset), {\"compute_time\": compute_time, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\n    def evaluate(self, parameters, config):\n        self.set_parameters(parameters)\n        model.eval()\n        loss = 0\n        correct = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss += criterion(outputs, labels).item()\n                _, predicted = torch.max(outputs.data, 1)\n                correct += (predicted == labels).sum().item()\n        accuracy = correct / len(val_loader.dataset)\n        return loss, len(val_loader.dataset), {\"accuracy\": accuracy, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\nfl.client.start_client(server_address=\"localhost:8080\", client=MNISTClient().to_client())", "modelCode": "import torch\nimport torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n        self.fc1 = nn.Linear(7*7*64, 1000)\n        self.fc2 = nn.Linear(1000, 10)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = x.view(-1, 7*7*64)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x", "amount": "0.00001", "id": 1720962406267}, {"clientCode": "import flwr as fl\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, Subset, random_split\nfrom torchvision import datasets, transforms\nfrom model import SimpleCNN\nimport time\nimport uuid\nimport random\n\nTOTAL_DATASET_SIZE = 1000  # Total number of images to use from MNIST\nDATASET_PERCENTAGE = 100\nMODEL_ID = ''\nETH_ADDRESS = ''\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = SimpleCNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\nfull_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n\n# Select a random subset of TOTAL_DATASET_SIZE from the full dataset\nindices = torch.randperm(len(full_dataset))[:TOTAL_DATASET_SIZE]\nsubset_dataset = Subset(full_dataset, indices)\n\n# Calculate the number of samples to use based on the percentage\nnum_samples = int(len(subset_dataset) * DATASET_PERCENTAGE / 100)\n\n# Create a stratified subset\nclass_indices = [[] for _ in range(10)]\nfor idx in indices:\n    _, label = full_dataset[idx]\n    class_indices[label].append(idx)\n\nsubset_indices = []\nfor class_idx in class_indices:\n    # Ensure that the sampling is within the bounds of each class's available indices\n    num_samples_per_class = int(len(class_idx) * DATASET_PERCENTAGE / 100)\n    subset_indices.extend(random.sample(class_idx, num_samples_per_class))\n\n# Correctly create the dataset from the subset indices\ndataset = Subset(full_dataset, subset_indices)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n\nclass MNISTClient(fl.client.NumPyClient):\n    def __init__(self):\n        super().__init__()\n        self.client_id = str(uuid.uuid4())\n\n    def get_parameters(self, config=None):\n        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        params_dict = zip(model.state_dict().keys(), parameters)\n        state_dict = {k: torch.tensor(v).to(device) for k, v in params_dict}\n        model.load_state_dict(state_dict)\n\n    def fit(self, parameters, config):\n        self.set_parameters(parameters)\n        model.train()\n        start_time = time.time()\n        for epoch in range(1):\n            for images, labels in train_loader:\n                images, labels = images.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n        compute_time = time.time() - start_time\n        return self.get_parameters(), len(train_loader.dataset), {\"compute_time\": compute_time, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\n    def evaluate(self, parameters, config):\n        self.set_parameters(parameters)\n        model.eval()\n        loss = 0\n        correct = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss += criterion(outputs, labels).item()\n                _, predicted = torch.max(outputs.data, 1)\n                correct += (predicted == labels).sum().item()\n        accuracy = correct / len(val_loader.dataset)\n        return loss, len(val_loader.dataset), {\"accuracy\": accuracy, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\nfl.client.start_client(server_address=\"localhost:8080\", client=MNISTClient().to_client())", "modelCode": "import torch\nimport torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n        self.fc1 = nn.Linear(7*7*64, 1000)\n        self.fc2 = nn.Linear(1000, 10)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = x.view(-1, 7*7*64)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x", "amount": "0.00001", "id": 1720962571721}, {"clientCode": "import flwr as fl\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, Subset, random_split\nfrom torchvision import datasets, transforms\nfrom model import SimpleCNN\nimport time\nimport uuid\nimport random\n\nTOTAL_DATASET_SIZE = 1000  # Total number of images to use from MNIST\nDATASET_PERCENTAGE = 100\nMODEL_ID = ''\nETH_ADDRESS = ''\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = SimpleCNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\nfull_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n\n# Select a random subset of TOTAL_DATASET_SIZE from the full dataset\nindices = torch.randperm(len(full_dataset))[:TOTAL_DATASET_SIZE]\nsubset_dataset = Subset(full_dataset, indices)\n\n# Calculate the number of samples to use based on the percentage\nnum_samples = int(len(subset_dataset) * DATASET_PERCENTAGE / 100)\n\n# Create a stratified subset\nclass_indices = [[] for _ in range(10)]\nfor idx in indices:\n    _, label = full_dataset[idx]\n    class_indices[label].append(idx)\n\nsubset_indices = []\nfor class_idx in class_indices:\n    # Ensure that the sampling is within the bounds of each class's available indices\n    num_samples_per_class = int(len(class_idx) * DATASET_PERCENTAGE / 100)\n    subset_indices.extend(random.sample(class_idx, num_samples_per_class))\n\n# Correctly create the dataset from the subset indices\ndataset = Subset(full_dataset, subset_indices)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n\nclass MNISTClient(fl.client.NumPyClient):\n    def __init__(self):\n        super().__init__()\n        self.client_id = str(uuid.uuid4())\n\n    def get_parameters(self, config=None):\n        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        params_dict = zip(model.state_dict().keys(), parameters)\n        state_dict = {k: torch.tensor(v).to(device) for k, v in params_dict}\n        model.load_state_dict(state_dict)\n\n    def fit(self, parameters, config):\n        self.set_parameters(parameters)\n        model.train()\n        start_time = time.time()\n        for epoch in range(1):\n            for images, labels in train_loader:\n                images, labels = images.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n        compute_time = time.time() - start_time\n        return self.get_parameters(), len(train_loader.dataset), {\"compute_time\": compute_time, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\n    def evaluate(self, parameters, config):\n        self.set_parameters(parameters)\n        model.eval()\n        loss = 0\n        correct = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss += criterion(outputs, labels).item()\n                _, predicted = torch.max(outputs.data, 1)\n                correct += (predicted == labels).sum().item()\n        accuracy = correct / len(val_loader.dataset)\n        return loss, len(val_loader.dataset), {\"accuracy\": accuracy, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\nfl.client.start_client(server_address=\"localhost:8080\", client=MNISTClient().to_client())", "modelCode": "import torch\nimport torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n        self.fc1 = nn.Linear(7*7*64, 1000)\n        self.fc2 = nn.Linear(1000, 10)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = x.view(-1, 7*7*64)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x", "amount": "0.00001", "id": 1720963271313}, {"clientCode": "import flwr as fl\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, Subset, random_split\nfrom torchvision import datasets, transforms\nfrom model import SimpleCNN\nimport time\nimport uuid\nimport random\n\nTOTAL_DATASET_SIZE = 1000  # Total number of images to use from MNIST\nDATASET_PERCENTAGE = 100\nMODEL_ID = ''\nETH_ADDRESS = ''\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = SimpleCNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\nfull_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n\n# Select a random subset of TOTAL_DATASET_SIZE from the full dataset\nindices = torch.randperm(len(full_dataset))[:TOTAL_DATASET_SIZE]\nsubset_dataset = Subset(full_dataset, indices)\n\n# Calculate the number of samples to use based on the percentage\nnum_samples = int(len(subset_dataset) * DATASET_PERCENTAGE / 100)\n\n# Create a stratified subset\nclass_indices = [[] for _ in range(10)]\nfor idx in indices:\n    _, label = full_dataset[idx]\n    class_indices[label].append(idx)\n\nsubset_indices = []\nfor class_idx in class_indices:\n    # Ensure that the sampling is within the bounds of each class's available indices\n    num_samples_per_class = int(len(class_idx) * DATASET_PERCENTAGE / 100)\n    subset_indices.extend(random.sample(class_idx, num_samples_per_class))\n\n# Correctly create the dataset from the subset indices\ndataset = Subset(full_dataset, subset_indices)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n\nclass MNISTClient(fl.client.NumPyClient):\n    def __init__(self):\n        super().__init__()\n        self.client_id = str(uuid.uuid4())\n\n    def get_parameters(self, config=None):\n        return [val.cpu().numpy() for _, val in model.state_dict().items()]\n\n    def set_parameters(self, parameters):\n        params_dict = zip(model.state_dict().keys(), parameters)\n        state_dict = {k: torch.tensor(v).to(device) for k, v in params_dict}\n        model.load_state_dict(state_dict)\n\n    def fit(self, parameters, config):\n        self.set_parameters(parameters)\n        model.train()\n        start_time = time.time()\n        for epoch in range(1):\n            for images, labels in train_loader:\n                images, labels = images.to(device), labels.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n        compute_time = time.time() - start_time\n        return self.get_parameters(), len(train_loader.dataset), {\"compute_time\": compute_time, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\n    def evaluate(self, parameters, config):\n        self.set_parameters(parameters)\n        model.eval()\n        loss = 0\n        correct = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss += criterion(outputs, labels).item()\n                _, predicted = torch.max(outputs.data, 1)\n                correct += (predicted == labels).sum().item()\n        accuracy = correct / len(val_loader.dataset)\n        return loss, len(val_loader.dataset), {\"accuracy\": accuracy, \"model_id\": MODEL_ID, \"eth_address\": ETH_ADDRESS}\n\nfl.client.start_client(server_address=\"localhost:8080\", client=MNISTClient().to_client())", "modelCode": "import torch\nimport torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n        self.fc1 = nn.Linear(7*7*64, 1000)\n        self.fc2 = nn.Linear(1000, 10)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = self.pool(torch.relu(self.conv2(x)))\n        x = x.view(-1, 7*7*64)\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x", "amount": "0.00001", "id": 1720963689553}]